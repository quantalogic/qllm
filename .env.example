# AWS Configuration
AWS_PROFILE=default
AWS_REGION=us-east-1

# Default LLM Provider
# Options: anthropic, openai, ollama
DEFAULT_PROVIDER=anthropic

# Model Configuration
# Use either MODEL_ALIAS or MODEL_ID, not both
MODEL_ALIAS=
MODEL_ID=

# OpenAI Configuration (required when using OpenAI provider)
OPENAI_API_KEY=

# Prompt Management
# Comma-separated list of directories to search for prompt templates
PROMPT_DIRECTORIES=~/.config/qllm/prompts,./prompts
# Specify the active prompt set
ACTIVE_PROMPT_SET=default

# Logging
LOG_LEVEL=info